## EN / [PL](#Cześć!)

# **Hello!**
If you've found yourself here, you're probably interested in my profile and projects – which I find very pleasing.

## **Current Work**
As a scientist and academic teacher at the Lublin University of Technology, I have 8 years of experience in scientific data analysis. My work focuses on using advanced programming tools, such as Python, for deep analysis and interpretation of complex datasets. I specialize in identifying correlations and trends in technical data, applicable in my research on the impact of ion implantation on the tribological properties of materials. I also enhance my analytical skills by conducting lectures and workshops, both domestically and internationally. More about my research can be found [here](https://scholar.google.com/citations?user=zoPbPawAAAAJ&hl=pl).
In the field of teaching, I cover subjects such as Telematics, Telematics in logistic systems, Construction of motor vehicles, Vehicle diagnostics, Operation of transport means.

## **My Aspirations**
I have always been fascinated by IT technologies. After obtaining my doctoral degree, I started to explore new knowledge areas including programming with Python for data analysis. This new passion completely absorbed me. The scripts I developed significantly accelerated the analysis of data in my research, which inspired me to further my education in this direction. Currently, I dedicate a significant portion of my time to learning about the possibilities of using ML and AI technologies in analysis and modeling. I see my future in the ML area, utilizing Artificial Neural Networks and other AI technologies for practical applications. I would like to work in Data Engineering, Data Analysis, and also as a Data Scientist.

Given that my job at the university allows for activities outside of it, I decided to fulfill my dreams and start making my way in the IT industry. I am open to new forms of professional development.

My projects to date are publicly available on this profile. I hope that by developing in programming, I can combine my passion with work on a commercial project.

## **TECHNICAL SKILLS:**
### **Python:** Advanced programming skills in Python, advanced knowledge of libraries such as Pandas, NumPy for data analysis, and Django for web development. Specializes in Scikit-learn for machine learning. Ability to integrate data via APIs and create advanced analytical pipelines.
### **Data analysis and visualization:** Proficiency in extracting insights from complex datasets using Python, Excel, and Statistica. Advanced skills in creating intuitive visualizations using Matplotlib and Seaborn. Basic knowledge of Power BI.
### **Jupyter Notebook:** Proficiency in using Jupyter Notebook for dynamic data analysis and visualization, combining code with narrative text and visualizations to achieve comprehensive analysis documentation.
### **Software development and deployment:** Knowledge of GitLab and CI/CD for software automation. Ability to work in Linux/Bash environment and Docker to create scalable, isolated application environments. Proficient in version control systems GIT/GitHub.
### **Database management:** Experience in managing relational databases, particularly PostgreSQL, with skills in optimizing SQL queries.
### **ML / AI:** Engaged in applying artificial intelligence and machine learning techniques using libraries such as TensorFlow and Scikit-learn to derive useful insights from data.
### **Foreign languages:** Fluent in English at C1 level, facilitating effective communication in an international environment.

## **Brief description of my projects**
### **Analysis and Modeling of Wholesale Fuel Prices (Pandas, Matplotlib, Seaborn, Scikit-learn, Numpy, Jupyter Notebook) (https://github.com/mariuszkam4/Orlen_fuel_prices):**
In this project, I analyzed the relationship between wholesale fuel prices, Brent crude oil prices, and the USD/PLN exchange rate to identify periods where Eurodiesel fuel prices did not reflect market situations. The project involved collecting and preparing data from various sources, exploratory data analysis including descriptive statistics and visualization of price trends, and developing predictive models using linear and polynomial regression. I conducted a comparative analysis of the model’s accuracy.

### **Surface Roughness Analysis of Control Valves for High-Pressure Fuel Injectors (Pandas, NumPy, Scikit-learn, TensorFlow, Matplotlib, Seaborn) - In Progress (https://github.com/mariuszkam4/Roughness-analysis):**
This project is dedicated to analyzing surface roughness parameters. It involves automated data extraction from PDF reports using Python, data cleaning, and normalization to prepare for exploratory data analysis (EDA) to discover patterns and anomalies. A key goal is to compare valves treated with ion implantation against standard valves using statistical and machine-learning techniques to identify significant differences in roughness.

### **Hair Salon - A Reservation Management System for a Hair Salon (https://github.com/mariuszkam4/hair_salon.git):**
The goal of this project is to create a web application for booking appointments in a hair salon. The system's backend was developed in Python using the Django framework. The database was created with PostgreSQL. The frontend was developed using HTML/CSS/JavaScript technologies. The final version of the project will be containerized using Docker containers. A separate container will house the database, and another will contain the application itself. The containers will be interconnected. The project's plans include its deployment using AWS.

### **Economic Data Analysis (Jupyter Notebook, Pandas, Matplotlib, FRED API) (https://github.com/mariuszkam4/Economic_data_analysis):**
I carried out an economic data analysis project in Jupyter Notebook, utilizing Pandas for data processing, Matplotlib and Plotly for visualization, and the FRED API for data retrieval. Key aspects include historical analysis of S&P 500 trends, visualization of state-level unemployment rates, and comparative analysis of unemployment and labor force participation rates. The project demonstrates proficiency in extracting, analyzing, and visually presenting complex economic data.

### **Friction Analyzer (Pandas, Matplotlib libraries) (https://github.com/mariuszkam4/friction_analyzer.git)**
A project to analyze measurement data collected during friction tests on a tribometer. The script processes CSV files at the specified location containing friction coefficient measurements, then calculates the moving average for each measurement and saves the results in a consolidated CSV file. Additionally, it visualizes the results in the form of a line graph.

### **Wear Analyzer (Pandas, Matplotlib libraries) (https://github.com/mariuszkam4/wear_analyzer.git)**
A tool for extracting data from CSV files containing results of surface parameter measurements. It allows the user to select a specific parameter from a list of available ones (length, maximum depth, hole area, maximum height, peak area), then aggregates the data and saves it in a consolidated CSV file. Additionally, the script visualizes the results in the form of a box plot.

### **Rental (Pandas libraries, json, pytest) (https://github.com/mariuszkam4/wypozyczalnia.git)**
A program to manage a car rental database. The user can add, delete, as well as rent and return vehicles. It is also possible to search the database based on selected criteria. The application uses Python modules, such as json and pandas, which makes it possible to store data in JSON format and manage it efficiently. User interaction is done through commands entered in the console. Unit tests have been implemented in the project, ensuring high code quality and application reliability.

### **Paper Browser (Flask, HTML, JavaScript) (https://github.com/mariuszkam4/paper_browser.git)**
A web application that integrates with the arXiv API, allowing users to browse and select scientific data for download. It enables users to search for publications by specified keywords and publication date. The backend was implemented in Python using the Flask framework, while the frontend is based on HTML and JavaScript.


# **Cześć!**
Jeśli znalazłeś się tutaj, to prawdopodobnie jesteś zainteresowany moim profilem i projektami – bardzo mnie to cieszy.

## **Aktualna praca**
Jako naukowiec i nauczyciel akademicki z Politechniki Lubelskiej, posiadam 8 lat doświadczenia w analizie danych naukowych. Moja praca koncentruje się na wykorzystaniu zaawansowanych narzędzi programistycznych, takich jak Python, do głębokiej analizy i interpretacji złożonych zbiorów danych. Specjalizuję się w identyfikowaniu korelacji i trendów w danych technicznych, co znajduje zastosowanie w moich badaniach nad wpływem implantacji jonowej na właściwości tribologiczne materiałów. Moje umiejętności analityczne rozwijam również poprzez prowadzenie wykładów i warsztatów, zarówno w kraju, jak i za granicą.Więcej na temat moich badań możesz przeczytać [tutaj](https://scholar.google.com/citations?user=zoPbPawAAAAJ&hl=pl).
W obszarze dydatkyki zajmuję się nauczaniem takich przedmiotów jak: Telematyka, Telematyka w systemach logistycznych, Budowa pojazdów samochodowych, Diagnostyka pojazdów, Ekspoatacja środków transportu. 

## **Moje aspiracje**
Od zawsze byłem zafascynowany technologiami IT. Po osiągnięciu stopnia doktora zacząłem eksplorować nowe obszary wiedzy w tym programowanie z wykorzystaniem języka Python do analizy danych. Nowa pasja pochłonęła mnie całkowiecie. Opracowane skrypty znacznie przyspieszyły analizę danych w moich badaniach, co zainspirowało mnie do dalszego kształcenia w tym kierunku. Obecnie znaczną część czasu poświęcam na pozwnanie możliwości wykorzystania techonologii ML i AI w analizie i modelowaniu. Swoją przyszłość łączę z obszarem ML, wykorzystaniem Sztucznych Sieci Neuronowych i innych technologii szeroko pojętej sztucznej inteligencji do zastosowań praktycznych. Chciałbym podjąć pracę w obszarze Data Engineering, Data Analysis, a także Data Scientist. 

W związku z tym, że praca na uczelni pozwala na podejmowanie aktywności poza nią, postanowiłem spełnić swoje marzenia i zacząć się realizować w branży IT. Jestem otwarty na nowe formy rozwoju zawodowego.

Moje dotychczasowe projekty są dostępne publicznie na tym profilu. Mam nadzieję, że rozwijając się w programowaniu, będę mógł połączyć swoją pasję z pracą w komercyjnym projekcie.

## UMIEJĘTNOŚCI TECHNICZNE:
###	**Python:** Zaawansowane umiejętności programowania w Pythonie, zaawansowana znajomość bibliotek takich jak Pandas, NumPy do analizy danych i Django do tworzenia stron internetowych. Specjalizuje się w Scikit-learn do uczenia maszynowego. Umiejętność integrowania danych za pośrednictwem interfejsów API i tworzenia zaawansowanych potoków analitycznych.
###	**Analiza danych i ich wizualizacja:** biegłość w wydobywaniu wniosków ze złożonych zbiorów danych przy użyciu Python, Excel i Statistica. Zaawansowany umiejętności w tworzeniu intuicyjnych wizualizacji przy użyciu Matplotlib i Seaborn. Podstawowa znajomość Power BI.
###	**Jupyter Notebook:** biegłość w wykorzystywaniu Jupyter Notebook do dynamicznej analizy i wizualizacji danych, łączenie kodu z tekstem narracyjnym i wizualizacjami w celu uzyskania kompleksowej dokumentacji analizy.
###	**Tworzenie i wdrażanie oprogramowania:** Znajomość GitLab i CI/CD do automatyzacji oprogramowania. Umiejętność pracy w środowisku Linux/Bash i Docker do tworzenia skalowalnych, izolowanych środowisk aplikacji. Biegła znajomość systemów kontroli wersji GIT/GitHub.
###	**Zarządzanie bazami danych:** Doświadczenie w zarządzaniu relacyjnymi bazami danych, w szczególności PostgreSQL, z umiejętnościami optymalizacji zapytań SQL.
###	**ML / AI:** Zaangażowany w stosowanie technik sztucznej inteligencji i uczenia maszynowego przy użyciu bibliotek takich jak TensorFlow i Scikit-learn w celu uzyskania przydatnych informacji z danych.
###	**Języki obce:** Biegła znajomość języka angielskiego na poziomie C1, ułatwiająca skuteczną komunikację w środowisku międzynarodowym.

## **Krótki opis moich projektów**
###	**Analiza i modelowanie hurtowych cen paliw (Pandas, Matplotlib, Seaborn, Scikit-learn, Numpy, Jupyter Notebook) (https://github.com/mariuszkam4/Orlen_fuel_prices):**
W ramach tego projektu przeanalizowałem związek między hurtowymi cenami paliw, cenami ropy Brent i kursem wymiany USD/PLN, mając na celu zidentyfikowanie okresów, w których ceny paliw Eurodiesel nie odzwierciedlały sytuacji rynkowej. Projekt obejmował zebranie i przygotowanie danych z różnych źródeł, eksploracyjną analizę danych obejmującą statystyki opisowe i wizualizację trendów cenowych oraz opracowanie modeli predykcyjnych z wykorzystaniem regresji liniowej i wielomianowej. Przeprowadziłem analizę porównawczą dokładności modelu. 
###	**Analiza chropowatości powierzchni zaworów sterujących wysokociśnieniowych wtryskiwaczy paliwa (Pandas, NumPy, Scikit-learn, TensorFlow, Matplotlib, Seaborn) - In Progress (https://github.com/mariuszkam4/Roughness-analysis):**
Projekt ten poświęcony jest analizie parametrów chropowatości powierzchni. Obejmuje on automatyczną ekstrakcję danych z raportów PDF przy użyciu Pythona, czyszczenie danych i normalizację w celu przygotowania do eksploracyjnej analizy danych (EDA) w celu odkrycia wzorców i anomalii. Kluczowym celem jest porównanie zaworów poddanych implantacji jonowej ze standardowymi zaworami przy użyciu technik statystycznych i uczenia maszynowego w celu zidentyfikowania znaczących różnic w chropowatości.
### **Hair salon - system obłsługi rezerwacji wizyt w salnie fryzjerskim (https://github.com/mariuszkam4/hair_salon.git):**
Celem projektu jest utworzenie aplikacji webowej do rezerwacji wizyt w salonie fryzjerskim. Backend systemu utworzony zostanał w języku Python z wykorzystaniem freamworka Django. Baza danych utworzona jest z wykorzystaniem PostgreSQL. Frontend aplikacji powstał przy wykorzystaniu technoligii HTML/CSS/JavaScript. Finalna wersja projektu zostanie skonteneryzowana z wykorzystaniem kontenerów Docker. W osobnym kontenerze umieszczona zostanie baza danych w osobnym aplikacja. Kontenery będą ze sobą połączone. Założenia projektu obejmują jego wdrożenie przy użyciu AWS.
### **Economic Data Analysis (Jupyter Notebook, Pandas, Matplotlib, FRED API) (https://github.com/mariuszkam4/Economic_data_analysis):**
Wykonałem projekt analizy danych ekonomicznych w Jupyter Notebook, wykorzystując Pandas do przetwarzania danych, Matplotlib i Plotly do wizualizacji oraz FRED API do pobierania danych. Kluczowe aspekty obejmują historyczną analizę trendów S&P 500, wizualizację stopy bezrobocia na poziomie stanowym oraz analizę porównawczą wskaźników bezrobocia i aktywności zawodowej. Projekt ilustruje biegłość w wydobywaniu, analizowaniu i wizualnej prezentacji złożonych danych ekonomicznych.
### **Friction analyzer (biblioteki Pandas, Matplotlib) (https://github.com/mariuszkam4/friction_analyzer.git)**
Projekt do analizy danych pomiarowych zebranych w trakcie badań tarcia na tribotesterze. Skrypt przetwarza pliki CSV we wskazanej lokalizacji zawierające wyniki pomiarów współczynnika tarcia, następnie oblicza średnią kroczącą z poszczególnych pomiarów, a wyniki zapisuje w zbiorczym pliku CSV. Dodatkowo wizualizuje wyniki w postaci wykresu liniowego.
###	**Wear analyzer** **(biblioteki Pandas, Matplotlib) (https://github.com/mariuszkam4/wear_analyzer.git)**
Narzędzie do ekstrakcji danych z plików CSV zawierających wyniki pomiarów paramterów powierzchni. Umożliwia ono użytkownikowi wybór konkretnego parametru z listy dostępnych (długość, maksymalna głębokość, pole otworu, maksymalna wysokość, obszar szczytu) następnie agreguje dane i zapisuje je w zbiorczym pliku CSV. Dodatkowo skrypt wizualizuje wyniki w postaci wykresu skrzynkowego.
###	**Wypożyczalnia (biblioteki Pandas, json, pytest) (https://github.com/mariuszkam4/wypozyczalnia.git)**
Program do zarządzania bazą samochodów w wypożyczalni. Użytkownik ma możliwość dodawania, usuwania, a także wypożyczania i zwracania pojazdów. Możliwe jest także przeszukiwanie bazy na podstawie wybranych kryteriów. Aplikacja korzysta z modułów Pythona, takich jak json i pandas, co umożliwia przechowywanie danych w formacie JSON oraz efektywne zarządzanie nimi. Interakcja z użytkownikiem odbywa się poprzez komendy wprowadzane w konsoli. W projekcie zaimplementowano testy jednostkowe, zapewniające wysoką jakość kodu i niezawodność aplikacji.
###	**Paper browser (Flask, HTML, JavaScript) (https://github.com/mariuszkam4/paper_browser.git)**
Aplikacja webowa, która integruje się z API arXiv, pozwalając użytkownikom na przeglądanie i selekcję danych naukowych do pobrania. Umożliwia wyszukiwanie publikacji wg podanych słów kluczowych oraz daty publikacji. Backend został zrealizowany w Python z wykorzystaniem frameworku Flask, podczas gdy frontend oparty jest na HTML i JavaScript.


